4. Metadata Routing — scikit-learn 1.7.0 documentation
Skip to main content
Back to top
Ctrl
+
K
Install
User Guide
API
Examples
Community
More
Getting Started
Release History
Glossary
Development
FAQ
Support
Related Projects
Roadmap
Governance
About us
GitHub
Choose version
Install
User Guide
API
Examples
Community
Getting Started
Release History
Glossary
Development
FAQ
Support
Related Projects
Roadmap
Governance
About us
GitHub
Choose version
Section Navigation
1. Supervised learning
1.1. Linear Models
1.2. Linear and Quadratic Discriminant Analysis
1.3. Kernel ridge regression
1.4. Support Vector Machines
1.5. Stochastic Gradient Descent
1.6. Nearest Neighbors
1.7. Gaussian Processes
1.8. Cross decomposition
1.9. Naive Bayes
1.10. Decision Trees
1.11. Ensembles: Gradient boosting, random forests, bagging, voting, stacking
1.12. Multiclass and multioutput algorithms
1.13. Feature selection
1.14. Semi-supervised learning
1.15. Isotonic regression
1.16. Probability calibration
1.17. Neural network models (supervised)
2. Unsupervised learning
2.1. Gaussian mixture models
2.2. Manifold learning
2.3. Clustering
2.4. Biclustering
2.5. Decomposing signals in components (matrix factorization problems)
2.6. Covariance estimation
2.7. Novelty and Outlier Detection
2.8. Density Estimation
2.9. Neural network models (unsupervised)
3. Model selection and evaluation
3.1. Cross-validation: evaluating estimator performance
3.2. Tuning the hyper-parameters of an estimator
3.3. Tuning the decision threshold for class prediction
3.4. Metrics and scoring: quantifying the quality of predictions
3.5. Validation curves: plotting scores to evaluate models
4. Metadata Routing
5. Inspection
5.1. Partial Dependence and Individual Conditional Expectation plots
5.2. Permutation feature importance
6. Visualizations
7. Dataset transformations
7.1. Pipelines and composite estimators
7.2. Feature extraction
7.3. Preprocessing data
7.4. Imputation of missing values
7.5. Unsupervised dimensionality reduction
7.6. Random Projection
7.7. Kernel Approximation
7.8. Pairwise metrics, Affinities and Kernels
7.9. Transforming the prediction target (
y
)
8. Dataset loading utilities
8.1. Toy datasets
8.2. Real world datasets
8.3. Generated datasets
8.4. Loading other datasets
9. Computing with scikit-learn
9.1. Strategies to scale computationally: bigger data
9.2. Computational Performance
9.3. Parallelism, resource management, and configuration
10. Model persistence
11. Common pitfalls and recommended practices
12. Dispatching
12.1. Array API support (experimental)
13. Choosing the right estimator
14. External Resources, Videos and Talks
User Guide
4.
Metadata Routing
4.
Metadata Routing
#
Note
The Metadata Routing API is experimental, and is not yet implemented for all
estimators. Please refer to the
list of supported and unsupported
models
for more information. It may change without
the usual deprecation cycle. By default this feature is not enabled. You can
enable it by setting the
enable_metadata_routing
flag to
True
:
>>>
import
sklearn
>>>
sklearn
.
set_config
(
enable_metadata_routing
=
True
)
Note that the methods and requirements introduced in this document are only
relevant if you want to pass
metadata
(e.g.
sample_weight
) to a method.
If you’re only passing
X
and
y
and no other parameter / metadata to
methods such as
fit
,
transform
, etc., then you don’t need to set
anything.
This guide demonstrates how
metadata
can be routed and passed between objects in
scikit-learn. If you are developing a scikit-learn compatible estimator or
meta-estimator, you can check our related developer guide:
Metadata Routing
.
Metadata is data that an estimator, scorer, or CV splitter takes into account if the
user explicitly passes it as a parameter. For instance,
KMeans
accepts
sample_weight
in its
fit()
method and considers it to calculate its centroids.
classes
are consumed by some classifiers and
groups
are used in some splitters, but
any data that is passed into an object’s methods apart from X and y can be considered as
metadata. Prior to scikit-learn version 1.3, there was no single API for passing
metadata like that if these objects were used in conjunction with other objects, e.g. a
scorer accepting
sample_weight
inside a
GridSearchCV
.
With the Metadata Routing API, we can transfer metadata to estimators, scorers, and CV
splitters using
meta-estimators
(such as
Pipeline
or
GridSearchCV
) or functions such as
cross_validate
which route data to other objects. In order to
pass metadata to a method like
fit
or
score
, the object consuming the metadata,
must
request
it. This is done via
set_{method}_request()
methods, where
{method}
is substituted by the name of the method that requests the metadata. For instance,
estimators that use the metadata in their
fit()
method would use
set_fit_request()
,
and scorers would use
set_score_request()
. These methods allow us to specify which
metadata to request, for instance
set_fit_request(sample_weight=True)
.
For grouped splitters such as
GroupKFold
, a
groups
parameter is requested by default. This is best demonstrated by the
following examples.
4.1.
Usage Examples
#
Here we present a few examples to show some common use-cases. Our goal is to pass
sample_weight
and
groups
through
cross_validate
, which
routes the metadata to
LogisticRegressionCV
and to a custom scorer
made with
make_scorer
, both of which
can
use the metadata in their
methods. In these examples we want to individually set whether to use the metadata
within the different
consumers
.
The examples in this section require the following imports and data:
>>>
import
numpy
as
np
>>>
from
sklearn.metrics
import
make_scorer
,
accuracy_score
>>>
from
sklearn.linear_model
import
LogisticRegressionCV
,
LogisticRegression
>>>
from
sklearn.model_selection
import
cross_validate
,
GridSearchCV
,
GroupKFold
>>>
from
sklearn.feature_selection
import
SelectKBest
>>>
from
sklearn.pipeline
import
make_pipeline
>>>
n_samples
,
n_features
=
100
,
4
>>>
rng
=
np
.
random
.
RandomState
(
42
)
>>>
X
=
rng
.
rand
(
n_samples
,
n_features
)
>>>
y
=
rng
.
randint
(
0
,
2
,
size
=
n_samples
)
>>>
my_groups
=
rng
.
randint
(
0
,
10
,
size
=
n_samples
)
>>>
my_weights
=
rng
.
rand
(
n_samples
)
>>>
my_other_weights
=
rng
.
rand
(
n_samples
)
4.1.1.
Weighted scoring and fitting
#
The splitter used internally in
LogisticRegressionCV
,
GroupKFold
, requests
groups
by default. However, we need
to explicitly request
sample_weight
for it and for our custom scorer by specifying
sample_weight=True
in
LogisticRegressionCV
’s
set_fit_request()
method and in
make_scorer
’s
set_score_request()
method. Both
consumers
know how to use
sample_weight
in their
fit()
or
score()
methods. We can then pass the metadata in
cross_validate
which will route it to any active consumers:
>>>
weighted_acc
=
make_scorer
(
accuracy_score
)
.
set_score_request
(
sample_weight
=
True
)
>>>
lr
=
LogisticRegressionCV
(
...
cv
=
GroupKFold
(),
...
scoring
=
weighted_acc
...
)
.
set_fit_request
(
sample_weight
=
True
)
>>>
cv_results
=
cross_validate
(
...
lr
,
...
X
,
...
y
,
...
params
=
{
"sample_weight"
:
my_weights
,
"groups"
:
my_groups
},
...
cv
=
GroupKFold
(),
...
scoring
=
weighted_acc
,
...
)
Note that in this example,
cross_validate
routes
my_weights
to both the scorer and
LogisticRegressionCV
.
If we would pass
sample_weight
in the params of
cross_validate
, but not set any object to request it,
UnsetMetadataPassedError
would be raised, hinting to us that we need to explicitly set
where to route it. The same applies if
params={"sample_weights":
my_weights,
...}
were passed (note the typo, i.e.
weights
instead of
weight
), since
sample_weights
was not requested by any of its underlying objects.
4.1.2.
Weighted scoring and unweighted fitting
#
When passing metadata such as
sample_weight
into a
router
(
meta-estimators
or routing function), all
sample_weight
consumers
require weights to be either explicitly requested or explicitly not
requested (i.e.
True
or
False
). Thus, to perform an unweighted fit, we need to
configure
LogisticRegressionCV
to not request sample weights, so
that
cross_validate
does not pass the weights along:
>>>
weighted_acc
=
make_scorer
(
accuracy_score
)
.
set_score_request
(
sample_weight
=
True
)
>>>
lr
=
LogisticRegressionCV
(
...
cv
=
GroupKFold
(),
scoring
=
weighted_acc
,
...
)
.
set_fit_request
(
sample_weight
=
False
)
>>>
cv_results
=
cross_validate
(
...
lr
,
...
X
,
...
y
,
...
cv
=
GroupKFold
(),
...
params
=
{
"sample_weight"
:
my_weights
,
"groups"
:
my_groups
},
...
scoring
=
weighted_acc
,
...
)
If
linear_model.LogisticRegressionCV.set_fit_request
had not been called,
cross_validate
would raise an error because
sample_weight
is passed but
LogisticRegressionCV
would not be explicitly
configured to recognize the weights.
4.1.3.
Unweighted feature selection
#
Routing metadata is only possible if the object’s method knows how to use the metadata,
which in most cases means they have it as an explicit parameter. Only then we can set
request values for metadata using
set_fit_request(sample_weight=True)
, for instance.
This makes the object a
consumer
.
Unlike
LogisticRegressionCV
,
SelectKBest
can’t consume weights and therefore no request
value for
sample_weight
on its instance is set and
sample_weight
is not routed
to it:
>>>
weighted_acc
=
make_scorer
(
accuracy_score
)
.
set_score_request
(
sample_weight
=
True
)
>>>
lr
=
LogisticRegressionCV
(
...
cv
=
GroupKFold
(),
scoring
=
weighted_acc
,
...
)
.
set_fit_request
(
sample_weight
=
True
)
>>>
sel
=
SelectKBest
(
k
=
2
)
>>>
pipe
=
make_pipeline
(
sel
,
lr
)
>>>
cv_results
=
cross_validate
(
...
pipe
,
...
X
,
...
y
,
...
cv
=
GroupKFold
(),
...
params
=
{
"sample_weight"
:
my_weights
,
"groups"
:
my_groups
},
...
scoring
=
weighted_acc
,
...
)
4.1.4.
Different scoring and fitting weights
#
Despite
make_scorer
and
LogisticRegressionCV
both expecting the key
sample_weight
, we can use aliases to pass different weights to different
consumers. In this example, we pass
scoring_weight
to the scorer, and
fitting_weight
to
LogisticRegressionCV
:
>>>
weighted_acc
=
make_scorer
(
accuracy_score
)
.
set_score_request
(
...
sample_weight
=
"scoring_weight"
...
)
>>>
lr
=
LogisticRegressionCV
(
...
cv
=
GroupKFold
(),
scoring
=
weighted_acc
,
...
)
.
set_fit_request
(
sample_weight
=
"fitting_weight"
)
>>>
cv_results
=
cross_validate
(
...
lr
,
...
X
,
...
y
,
...
cv
=
GroupKFold
(),
...
params
=
{
...
"scoring_weight"
:
my_weights
,
...
"fitting_weight"
:
my_other_weights
,
...
"groups"
:
my_groups
,
...
},
...
scoring
=
weighted_acc
,
...
)
4.2.
API Interface
#
A
consumer
is an object (estimator, meta-estimator, scorer, splitter) which
accepts and uses some
metadata
in at least one of its methods (for instance
fit
,
predict
,
inverse_transform
,
transform
,
score
,
split
).
Meta-estimators which only forward the metadata to other objects (child estimators,
scorers, or splitters) and don’t use the metadata themselves are not consumers.
(Meta-)Estimators which route metadata to other objects are
routers
.
A(n) (meta-)estimator can be a
consumer
and a
router
at the same time.
(Meta-)Estimators and splitters expose a
set_{method}_request
method for each method
which accepts at least one metadata. For instance, if an estimator supports
sample_weight
in
fit
and
score
, it exposes
estimator.set_fit_request(sample_weight=value)
and
estimator.set_score_request(sample_weight=value)
. Here
value
can be:
True
: method requests a
sample_weight
. This means if the metadata is provided,
it will be used, otherwise no error is raised.
False
: method does not request a
sample_weight
.
None
: router will raise an error if
sample_weight
is passed. This is in almost
all cases the default value when an object is instantiated and ensures the user sets
the metadata requests explicitly when a metadata is passed. The only exception are
Group*Fold
splitters.
"param_name"
: alias for
sample_weight
if we want to pass different weights to
different consumers. If aliasing is used the meta-estimator should not forward
"param_name"
to the consumer, but
sample_weight
instead, because the consumer
will expect a param called
sample_weight
. This means the mapping between the
metadata required by the object, e.g.
sample_weight
and the variable name provided
by the user, e.g.
my_weights
is done at the router level, and not by the consuming
object itself.
Metadata are requested in the same way for scorers using
set_score_request
.
If a metadata, e.g.
sample_weight
, is passed by the user, the metadata request for
all objects which potentially can consume
sample_weight
should be set by the user,
otherwise an error is raised by the router object. For example, the following code
raises an error, since it hasn’t been explicitly specified whether
sample_weight
should be passed to the estimator’s scorer or not:
>>>
param_grid
=
{
"C"
:
[
0.1
,
1
]}
>>>
lr
=
LogisticRegression
()
.
set_fit_request
(
sample_weight
=
True
)
>>>
try
:
...
GridSearchCV
(
...
estimator
=
lr
,
param_grid
=
param_grid
...
)
.
fit
(
X
,
y
,
sample_weight
=
my_weights
)
...
except
ValueError
as
e
:
...
print
(
e
)
[sample_weight] are passed but are not explicitly set as requested or not
requested for LogisticRegression.score, which is used within GridSearchCV.fit.
Call `LogisticRegression.set_score_request({metadata}=True/False)` for each metadata
you want to request/ignore. See the Metadata Routing User guide
<https://scikit-learn.org/stable/metadata_routing.html> for more information.
The issue can be fixed by explicitly setting the request value:
>>>
lr
=
LogisticRegression
()
.
set_fit_request
(
...
sample_weight
=
True
...
)
.
set_score_request
(
sample_weight
=
False
)
At the end of the
Usage Examples
section, we disable the configuration flag for
metadata routing:
>>>
sklearn
.
set_config
(
enable_metadata_routing
=
False
)
4.3.
Metadata Routing Support Status
#
All consumers (i.e. simple estimators which only consume metadata and don’t
route them) support metadata routing, meaning they can be used inside
meta-estimators which support metadata routing. However, development of support
for metadata routing for meta-estimators is in progress, and here is a list of
meta-estimators and tools which support and don’t yet support metadata routing.
Meta-estimators and functions supporting metadata routing:
sklearn.calibration.CalibratedClassifierCV
sklearn.compose.ColumnTransformer
sklearn.compose.TransformedTargetRegressor
sklearn.covariance.GraphicalLassoCV
sklearn.ensemble.StackingClassifier
sklearn.ensemble.StackingRegressor
sklearn.ensemble.VotingClassifier
sklearn.ensemble.VotingRegressor
sklearn.ensemble.BaggingClassifier
sklearn.ensemble.BaggingRegressor
sklearn.feature_selection.RFE
sklearn.feature_selection.RFECV
sklearn.feature_selection.SelectFromModel
sklearn.feature_selection.SequentialFeatureSelector
sklearn.impute.IterativeImputer
sklearn.linear_model.ElasticNetCV
sklearn.linear_model.LarsCV
sklearn.linear_model.LassoCV
sklearn.linear_model.LassoLarsCV
sklearn.linear_model.LogisticRegressionCV
sklearn.linear_model.MultiTaskElasticNetCV
sklearn.linear_model.MultiTaskLassoCV
sklearn.linear_model.OrthogonalMatchingPursuitCV
sklearn.linear_model.RANSACRegressor
sklearn.linear_model.RidgeClassifierCV
sklearn.linear_model.RidgeCV
sklearn.model_selection.GridSearchCV
sklearn.model_selection.HalvingGridSearchCV
sklearn.model_selection.HalvingRandomSearchCV
sklearn.model_selection.RandomizedSearchCV
sklearn.model_selection.permutation_test_score
sklearn.model_selection.cross_validate
sklearn.model_selection.cross_val_score
sklearn.model_selection.cross_val_predict
sklearn.model_selection.learning_curve
sklearn.model_selection.validation_curve
sklearn.multiclass.OneVsOneClassifier
sklearn.multiclass.OneVsRestClassifier
sklearn.multiclass.OutputCodeClassifier
sklearn.multioutput.ClassifierChain
sklearn.multioutput.MultiOutputClassifier
sklearn.multioutput.MultiOutputRegressor
sklearn.multioutput.RegressorChain
sklearn.pipeline.FeatureUnion
sklearn.pipeline.Pipeline
sklearn.semi_supervised.SelfTrainingClassifier
Meta-estimators and tools not supporting metadata routing yet:
sklearn.ensemble.AdaBoostClassifier
sklearn.ensemble.AdaBoostRegressor
previous
3.5.
Validation curves: plotting scores to evaluate models
next
5.
Inspection
On this page
4.1. Usage Examples
4.1.1. Weighted scoring and fitting
4.1.2. Weighted scoring and unweighted fitting
4.1.3. Unweighted feature selection
4.1.4. Different scoring and fitting weights
4.2. API Interface
4.3. Metadata Routing Support Status
This Page
Show Source
© Copyright 2007 - 2025, scikit-learn developers (BSD License).